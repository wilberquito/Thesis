# Regularization techniques[^1]

Why did we not figure out earlier that deep models are effective? There are many reasons, one reason is that deep models only really shine if you have enough data to train them. An other reason is now we now know better today how to train very big models using better regularization techniques.

A deep network that's just the right size for your data is very, very hard to optimize. In practice, we always try networks that are way to big for our data and then we try our best to prevent them from over-fitting.

## Early termination[^2]

The first way we prevent over fitting is by looking at the performance in the validation set and stopping in train as soon as we stop improving. This is the best way to prevent the network from over optimizing in training set.

[![Udacity](../_images/DNN-earlytermination.png)](https://classroom.udacity.com/courses/ud730/lessons/14e8621e-bc7f-4df6-a05a-df6a695c9791/concepts/ca710a33-f75e-4847-878f-1db635dad608)

## What is Regularization in ML?

Regularization is an approach to address over-fitting in ML. Over-fitted model fails to generalize estimations on test data, regularization reduces the variance of the model.

Regularizing means applying artificial constrains on the network that implicitly reduce the number of free parameters. While not making it more difficult to optimize, also, an effective regularizer is one that makes a profitable-trade, reducing variance significantly while not overly increasing the bias.

## How to introduce regularization in deep learning

The simplest way of introducing regularization is modifying the loss function. The most common family of approaches used are parameters norm penalties. Here for example, we add a parameter norm penalty of the form $\Omega(\theta)$ to the loss function $J(\theta;X,y)$.

$$ J'(\theta;X,y) = J(\theta;X,y) + \alpha\Omega(\theta) $$

Where $\alpha$ is a hyperparameter which values are $alpha >= 0$ and rules the weights from the contribution of function penalty, hence the effect of the regularization.

## L2 Regularization

Also known as weight decay or ridge regression, adds a norm penalty in the form of $\Omega(\theta) = ||w||^{2}_{2}$. Where $||w||^2_2$ is the sum of the squares of all the attribute weights, for example $||w||^2_2 = w_1^2 + w_2^2 + ... + w_n^2$.

The loss function has been transformed to:

$$ J'(w;X,y) = J(w;X,y) + \alpha||w||^{2}_{2} $$

An equivalent expression is the following:

$$ J'(w;X,y) = J(w;X,y) + \alpha\sum_{j}w_{j}^{2} $$

The L2 regularizer will have a big impact on the directions of the weight vector that don’t “contribute” much to the loss function. On the other hand, it will have a relatively small effect on the directions that contribute to the loss function. As a result, we reduce the variance of our model, which makes it easier to generalize on unseen data.

## L1 Regularization

Also known as Lasso, prevents the weights from getting too large (defined by L1 norm). Larger the weights, more complex the model is, more chances of over-fitting. L1 regularization introduces sparsity in the weights. It forces more weights to be zero than reducing the the average magnitude of all weights.

Lasso norm penalty is expressed as:

$$ \Omega(\theta) = ||w||_{1} \hspace{1em} or \hspace{1em} \Omega(\theta) = \sum_{i}|w_{i}| $$

Hence the loss function is expressed as:

$$ J'(w;X,y) = J(w;X,y) + \alpha||w||_{1} $$

An equivalent expression is the following:

$$ J'(w;X,y) = J(w;X,y) + \alpha\sum_{i}|w_{i}| $$

## Elastic net Regularization

It's a mix between L1 and L2...

[^1]: [Regularization techniques for training deep neural networks](https://theaisummer.com/regularization/).

[^2]: [Early Termination](https://classroom.udacity.com/courses/ud730/lessons/14e8621e-bc7f-4df6-a05a-df6a695c9791/concepts/ca710a33-f75e-4847-878f-1db635dad608)

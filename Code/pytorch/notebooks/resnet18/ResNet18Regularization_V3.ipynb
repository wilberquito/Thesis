{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOC/ZZLwcZ49eBCQP+AZuLR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wilberquito/Thesis/blob/main/Code/pytorch/notebooks/resnet18/ResNet18Regularization_V3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0yf8OXuYKe-"
      },
      "outputs": [],
      "source": [
        "!pip install wandb >/dev/null 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import torchmetrics, mlxtend\n",
        "    print(f\"mlxtend version: {mlxtend.__version__}\")\n",
        "    assert int(mlxtend.__version__.split(\".\")[1]) >= 19, \"mlxtend verison should be 0.19.0 or higher\"\n",
        "except:\n",
        "    !pip install -q torchmetrics -U mlxtend # <- Note: If you're using Google Colab, this may require restarting the runtime\n",
        "    import torchmetrics, mlxtend\n",
        "    print(f\"mlxtend version: {mlxtend.__version__}\")"
      ],
      "metadata": {
        "id": "TMY_Bn5cYWxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from zipfile import ZipFile\n",
        "\n",
        "try:\n",
        "    import google.colab\n",
        "    from google.colab import drive\n",
        "    IN_COLAB = True\n",
        "    drive.mount('/content/drive')\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "\n",
        "print(f\"In colab: {IN_COLAB}\")"
      ],
      "metadata": {
        "id": "Moi9AJc3YYch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pull_code():\n",
        "  print(\"Unzipping the code from google drive\")\n",
        "  !rm -rf modular/\n",
        "  !unzip ./drive/MyDrive/wilberquito_thesis/modular.zip -d . >/dev/null 2>&1\n",
        "\n",
        "if IN_COLAB:\n",
        "    pull_code()"
      ],
      "metadata": {
        "id": "WkSOCpJ0YZ3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pull_data():\n",
        "  answer = input(\"You sure? Y/n\\n\")\n",
        "  if answer != \"Y\":\n",
        "    return\n",
        "\n",
        "  print(\"Unzipping the data from google drive\")\n",
        "  !rm -rf data.etl/\n",
        "  !unzip ./drive/MyDrive/wilberquito_thesis/data.zip -d . >/dev/null 2>&1\n",
        "\n",
        "if IN_COLAB:\n",
        "    pull_data()"
      ],
      "metadata": {
        "id": "wglDxVr2Ybqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "FEkHHlfiYdOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scheduler"
      ],
      "metadata": {
        "id": "XXyohae1Ye2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LEARNING_RATE = 1e-3\n",
        "EPOCHS = 20\n",
        "T_0 = 5\n",
        "T_MULT = 1\n",
        "ETA_MIN = 1e-4"
      ],
      "metadata": {
        "id": "H4CjcuAeY06l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim.lr_scheduler as lr_scheduler # Import your choice of scheduler here\n",
        "import modular.utility as m_utility\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set model and optimizer\n",
        "model = torch.nn.Linear(2, 1)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# Define your scheduler here as described above\n",
        "scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,\n",
        "                                                     T_0 = T_0,# Number of iterations for the first restart\n",
        "                                                     T_mult = T_MULT, # A factor increases TiTi​ after a restart\n",
        "                                                     eta_min = ETA_MIN) # Minimum learning rate\n",
        "\n",
        "m_utility.plot_learning_rate_scheduler(optimizer,\n",
        "                                       scheduler,\n",
        "                                       LEARNING_RATE,\n",
        "                                       EPOCHS)"
      ],
      "metadata": {
        "id": "HICfCCisYu0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Batch Size"
      ],
      "metadata": {
        "id": "ga6bbWAcY3Fc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 1024"
      ],
      "metadata": {
        "id": "mM3acDSnY2ny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## WandB"
      ],
      "metadata": {
        "id": "RDD3ODnIY-mx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "key = \"c1121fe51146c1da87d1139239da7748c4e78665\"\n",
        "wandb.login(key=key)"
      ],
      "metadata": {
        "id": "0WKKorQZZAZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "metadata": {
        "id": "NWlG8U4VZCck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(\n",
        "    # set the wandb project where this run will be logged\n",
        "    project=\"melanoma_thesis\",\n",
        "    group=\"train_test\",\n",
        "    name=\"ResNet18_V3\",\n",
        "    config={\n",
        "      \"architecture\": \"ResNet18\",\n",
        "      \"scheduler\": \"CosineAnnealingWarmRestarts\",\n",
        "      \"dataset\": \"ISIC\",\n",
        "      \"learning_rate\": LEARNING_RATE,\n",
        "      \"batch_size\": BATCH_SIZE,\n",
        "      \"epochs\": EPOCHS,\n",
        "      \"eta_min\": ETA_MIN,\n",
        "      \"t_0\": T_0,\n",
        "      \"t_mult\": T_MULT\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "lCpHCc9tZD38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Writter"
      ],
      "metadata": {
        "id": "0T1TvEvTZJjw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import modular.utility as m_utility\n",
        "\n",
        "writter = m_utility.model_writter('resnet18_v3')"
      ],
      "metadata": {
        "id": "TL0nsjHEZH8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "xcDaZwD2ZW5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torchvision.models import (ResNet18_Weights)\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "import torchvision as tv\n",
        "import modular.dataset as m_dataset\n",
        "import modular.utility as m_utility\n",
        "import modular.engine as engine\n",
        "import modular.models as m_models\n",
        "\n",
        "# Set seed\n",
        "m_utility.set_seed(42)\n",
        "\n",
        "# Build the dataframes\n",
        "data_dir = 'data.etl'\n",
        "data_folder = '512'\n",
        "train_df, test_df, mapping = m_dataset.get_df(data_dir, data_folder)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "out_features = len(mapping)\n",
        "model = m_models.ResNet18_Melanoma(out_features)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9)\n",
        "\n",
        "scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,\n",
        "                                                     T_0 = T_0,# Number of iterations for the first restart\n",
        "                                                     T_mult = T_MULT, # A factor increases TiTi​ after a restart\n",
        "                                                     eta_min = ETA_MIN) # Minimum learning rat\n",
        "\n",
        "# Mapping from id to classname\n",
        "idx_to_class = { k : classname for classname, k in mapping.items() }\n",
        "\n",
        "# Train and validate dataset & dataloader\n",
        "train_df, validate_df = m_dataset.train_validate_split(train_df,\n",
        "                                                       random_state=42,\n",
        "                                                       validate_size=0.2)\n",
        "\n",
        "validate_df, test_df = m_dataset.train_validate_split(validate_df,\n",
        "                                                      random_state=42,\n",
        "                                                      validate_size=0.5)\n",
        "\n",
        "\n",
        "train_transforms, val_transforms = m_dataset.get_transforms(image_size=256)\n",
        "train_transforms = val_transforms\n",
        "\n",
        "train_dataset = m_dataset.MelanomaDataset(train_df,\n",
        "                                          mode='train',\n",
        "                                          transforms=train_transforms,\n",
        "                                          idx_to_class=idx_to_class)\n",
        "validate_dataset = m_dataset.MelanomaDataset(validate_df,\n",
        "                                             mode='validate',\n",
        "                                             transforms=val_transforms,\n",
        "                                             idx_to_class=idx_to_class)\n",
        "\n",
        "batch_size = BATCH_SIZE\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "validate_dataloader = DataLoader(validate_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Test dataset and dataloader\n",
        "test_dataset = m_dataset.MelanomaDataset(test_df,\n",
        "                                         mode='test',\n",
        "                                         idx_to_class=idx_to_class)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Dataloaders\n",
        "dataloaders = {\n",
        "    'train': train_dataloader,\n",
        "    'val': validate_dataloader,\n",
        "}\n",
        "\n",
        "datasets_size = {\n",
        "    'train': len(train_dataset),\n",
        "    'val': len(validate_dataset),\n",
        "}\n",
        "\n",
        "about_data = {\n",
        "    'dataloaders': dataloaders,\n",
        "    'datasets': {\n",
        "        'size': datasets_size\n",
        "    }\n",
        "}\n",
        "\n",
        "MEL_IDX = 6 # Check data exploration notebook\n",
        "VAL_TIMES = 4\n",
        "\n",
        "model_ft, stats = engine.train_model(model,\n",
        "                                     MEL_IDX,\n",
        "                                     about_data,\n",
        "                                     device,\n",
        "                                     criterion,\n",
        "                                     optimizer,\n",
        "                                     scheduler,\n",
        "                                     num_epochs=EPOCHS,\n",
        "                                     writter=writter,\n",
        "                                     val_times=VAL_TIMES)"
      ],
      "metadata": {
        "id": "SytCLpEXZVJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "metadata": {
        "id": "sE1XSoiPZcSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m_utility.plot_curves(stats)"
      ],
      "metadata": {
        "id": "hw8-nOK9Zey-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if IN_COLAB:\n",
        "  from google.colab import files\n",
        "  files.download('resnet18regularization_v3.pth.tar')\n",
        "  files.download('resnet18regularization_v3.csv')"
      ],
      "metadata": {
        "id": "YleIeCTYZgOA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
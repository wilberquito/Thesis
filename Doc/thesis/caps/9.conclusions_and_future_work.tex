\chapter{Conclusions and Future Work}
\label{cap:concl}

The main goal of this thesis was to utilize deep learning techniques to train
multiple models for detecting melanoma in an imbalanced dataset of dermoscopy
images. Once the models were trained, they were made accessible through a
micro-service architecture, which consisted of two components: an API exposing
the models and a user interface (UI) for interacting with the API. The training
process involved developing eight distinct models, all leveraging transfer
learning with the ResNet-18 pre-trained model as the foundation. Some models
only modified the fully-connected layer of ResNet-18 to classify among eight
classes, while others incorporated more intricate fully connected layers with
Dropout. \\


During the training of these eight models, various hyper-parameters and learning
policies were experimented with, including the use of schedulers. The models
were categorized into two groups: one with any additional regularization and
another with extra regularization, like data augmentation and dropout layers.


\begin{table}[H]
\centering
\begin{tabular}{lc|lc}
    \toprule
  \textbf{Model} & \textbf{Test AUC} & \cellcolor{gray!50}\textbf{Model} & \cellcolor{gray!50}\textbf{Test AUC}  \\
\midrule
 M0 & 0.892 & \cellcolor{gray!50}M4 & \cellcolor{gray!50}0.858 \\
 M1 $\star$ & 0.892 & \cellcolor{gray!50}M5 $\star$ & \cellcolor{gray!50}0.843 \\
 M2 $\ast$ &  0.885 &  \cellcolor{gray!50}M6 $\ast$ & \cellcolor{gray!50}0.848 \\
 M3 $\bullet$ & 0.886 & \cellcolor{gray!50}M7 $\bullet$ & \cellcolor{gray!50}0.849 \\
 \midrule
Mean &  88.875\% & \cellcolor{gray!50}Mean & \cellcolor{gray!50}84.950\%  \\
SD &  0.377\%  &   \cellcolor{gray!50}SD &  \cellcolor{gray!50}0.625\%  \\

\bottomrule
\end{tabular}
\caption[Models Metrics in Test Dataset]
  {\textit{Models Metrics in Test Dataset.}}
{\label{table:test-set-resume-metrics}}
\end{table}

The first group of models, which did not have extra regularization,
demonstrated superior performance with a mean AUC metric of 88.875\% and a
standard deviation of ±0.377\% on the test set. However, it was evident that
these models suffered from over-fitting during training, as indicated by their
performance on the validation set. On the other hand, the second group of
models, which were trained with additional regularization, achieved lower
results compared to the first group. Nevertheless, these models did not
experience over-fitting, suggesting the potential for better results with longer
training epochs. The second group of models achieved an average AUC of 84.950\%
with a standard deviation of ±0.625\%. \\

As for the increase in the standard deviation in the second group of models, we
attribute it to the effect of using more epochs, making the behavior of the
schedulers more notable. \\

While the models were in the training phase, we took the opportunity to develop
the CAD (Computer-Aided Diagnosis) infrastructure to support the project. For
the API, we opted for a soft-configuration approach, where the configurations
are specified through file-based configurations, providing flexibility and ease
of management. Additionally, we designed a simple and intuitive user interface
(UI) to streamline the interaction of healthcare professionals with the exposed
models. \\

Furthermore, we achieved a significant milestone by successfully implementing a
mechanism for deploying the models and services using containers. By leveraging
containers, we ensured that the entire CAD architecture could be easily
replicated and deployed across different environments. To further simplify the
setup process, we also developed a shell script capable of downloading the
necessary images and initiating the container services effectively. \\

This approach combined both research and engineering efforts, enabling us to
make sophisticated knowledge accessible to a wider audience. By integrating
cutting-edge research and engineering principles, we have created a powerful
tool for medical professionals, providing them with advanced diagnostic
capabilities to improve patient care and outcomes. \\

As we assess the current state of the CAD infrastructure, we recognize that
there are several potential implementations that could enhance its
capabilities. A fundamental aspect of the CAD infrastructure involves training
models and conducting comparative evaluations among them. \\

One promising approach is to establish a mechanism for iterative model
training, continuously monitoring and tracking their performance. The models
that demonstrate exceptional behavior could be promptly exposed and made
available for use. In the user interface (UI), we can provide professionals
with access to the training results of the models, including instances where
the selected model may not have performed optimally. By offering this
additional information, we aim to instill confidence in professionals so they
don't rely blindly on the models' inferences. \\

It's crucial to emphasize this CAD infrastructure is a tool, not a
replacement for human expertise. The presence of a skilled professional remains
indispensable to interpret and contextualize the results generated by the
models.
